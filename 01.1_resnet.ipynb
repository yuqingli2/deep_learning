{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/Practicum_AI_Logo.white_outline.svg' width=250 alt='Practicum AI logo'> <img src='https://github.com/PracticumAI/practicumai.github.io/blob/main/images/icons/practicumai_beginner.png?raw=true' align='right' width=50>\n",
    "***\n",
    "# *Practicum AI:* Deep Learning - Resnet\n",
    "\n",
    "This exercise adapted from Baig et al. (2020) <i>The Deep Learning Workshop</i> from <a href=\"https://www.packtpub.com/product/the-deep-learning-workshop/9781839219856\">Packt Publishers</a> (Exercise 1.01, page 7).\n",
    "\n",
    "## Deep learning for image recognition\n",
    "\n",
    "Before we dive into the details of how deep learning works, let's explore it through an example. In this exercise, we will use a pre-trained deep learning model, [ResNet50](https://arxiv.org/abs/1512.03385), which has been trained on [ImageNet](https://image-net.org/), a collection of about 1.3 million images labeled as being in one of 1,000 categories. \n",
    "\n",
    "To help with this exercise, let us introduce you to Amelia. <img alt='A GAN-generated cartoon image of Amelia, our character for this exercise.' src='images/amelia.png' align='right' width=300 style=\"float: right; padding: 10px 0px 0px 10px\">\n",
    "\n",
    "Amelia, our tech-geek, teenaged heroine, happens to be an extremely picky eater, who is a pizza fanatic üçï. When dinner time rolls around, she only wants to come down from her bedroom if pizza is on the menu. \n",
    "\n",
    "Being a tech-geek, Amelia has installed a hidden camera in the dining room.  Once dinner is set, the camera snaps a photo of the meal.  Now, she wants to develop an AI image recognition system to determine if pizza is served or not.  \n",
    "\n",
    "Let's help Amelia code her pizza recognition system!\n",
    "\n",
    "As a side note, the drawing of Amelia was generated by a Generative Adversarial Network (GAN) trained on Anime images and created at: [https://thisanimedoesnotexist.ai/](https://thisanimedoesnotexist.ai/). To learn more about GANs, check out our [Practicum AI GAN learning experience](https://github.com/PracticumAI/gan).\n",
    "\n",
    "#### 1. Import libraries\n",
    "\n",
    "Import the necessary libraries. For this exercise, Amelia will use the pre-trained ResNet50 model that is part of Keras: `from tensorflow.keras.applications.resnet50 import ResNet50`. Check out the [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50) for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the supporting libraries...\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
    "\n",
    "# Import base tensorflow and set seed to achieve consistent results.\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "seed = 42  # Set the seed for reproducibility\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Instantiate the Resnet50 model\n",
    "\n",
    "Instantiate the Resnet50 model as a variable. This step creates the instance of the model to use.\n",
    "\n",
    "\n",
    "#### <img src='images/tip_icon.svg' alt=\"Tip icon\" width=40 align=center> Tip\n",
    ">You will likely see some output highlighted in red. While red is used for errors, it is also used for warnings. It can take some getting used to, but red is OK in this case...\n",
    "\n",
    "```python\n",
    "mymodel = ResNet50()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load image\n",
    "\n",
    "Amelia has a test image of her favorite pizza to use to test the system. Let's load her pizza image in.\n",
    "\n",
    "Since ResNet50 was trained using images that are 224X224 pixels, we need to transform the input image to be the same size.\n",
    "\n",
    "### <img src='images/tip_icon.svg' alt=\"Tip icon\" width=40 align=center> Tip\n",
    "\n",
    ">The pizza image is stored in the images folder, the complete path of the location where the image is located must be given.\n",
    "<br><br>\n",
    "If running on Google Colab, you have a couple of choices:\n",
    "> 1. Change the `'images/pizza.jpg'` to use the web location of the image in this repository: `'https://raw.githubusercontent.com/PracticumAI/deep_learning/main/images/pizza.jpg'`\n",
    "> 2. Find any image of pizza, and upload it using the Files tab as in the image below. Then right click and \"Copy path\", and use that path.\n",
    "<br>\n",
    "<img src='images/colab_img_upload.png' alt='Screenshot of image upload for Google Colab'>\n",
    "    \n",
    "\n",
    "```python\n",
    "myimage = load_img('images/pizza.jpg', target_size = (224, 224))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. View the pizza image\n",
    "\n",
    "Let's take a quick look at the image to verify that it's a pizza.  Type the variable name and run the code block.\n",
    "\n",
    "```python\n",
    "myimage\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Convert image to array\n",
    "\n",
    "Convert the image to an array because the model expects it in this format.\n",
    "\n",
    "```python\n",
    "myimage = img_to_array(myimage)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Reshape image\n",
    "\n",
    "Reshape the image.  All images fed to this model need to be 224 pixels high and 224 pixels wide, with 3 channels, one for each color (Red, Green, Blue).  If our image was greyscale, how many channels would we specify?\n",
    "\n",
    "```python\n",
    "myimage = myimage.reshape((1, 224, 224, 3))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Pre-process image\n",
    "\n",
    "Execute the *preprocess_image()* function with the image.\n",
    "\n",
    "```python\n",
    "myimage = preprocess_input(myimage)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Execute predict method\n",
    "\n",
    "Execute the model's predict method.\n",
    "\n",
    "```python\n",
    "myresult = mymodel.predict(myimage)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Get prediction label\n",
    "\n",
    "The model's predict method returns a number.  Convert this to its corresponding text label.\n",
    "\n",
    "```python\n",
    "mylabel = decode_predictions(myresult)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Assign list item to variable \n",
    "\n",
    "Assign the first list item to a variable - this is the label with the highest probability.\n",
    "\n",
    "```python\n",
    "mylabel = mylabel[0][0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Embed label \n",
    "\n",
    "Embed the label in a sentence and then print it.\n",
    "\n",
    "```python\n",
    "print(\"This is an image of a \" + mylabel[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src='images/tip_icon.svg' alt=\"Tip icon\" width=40 align=center> Tip\n",
    "\n",
    "> Although we use an image of a pizza here, you can use just about any image with this model.  Continue on to step 16 where we define a function with all the steps. The <a href='https://raw.githubusercontent.com/PracticumAI/deep_learning/main/resnet_labels.txt'>resne> t_labels.txt</a> file lists all the images this model is trained to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Create a speech sentence\n",
    "\n",
    "Create a longer sentence to convert to speech.\n",
    "\n",
    "```python\n",
    "sayit = \"This is an image of a \" + mylabel[1] + \" in full living color.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Import gtts libraries\n",
    "\n",
    "Import the required libraries.  Google Text to Speech (gtts) is an open source cloud-based application programming interface (API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Execute the gtts function\n",
    "\n",
    "Pass the sayit variable to the gTTS API.\n",
    "\n",
    "```python\n",
    "myobj = gTTS(text = sayit)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Save the audio file\n",
    "\n",
    "Save the audio file.  The default location is the current directory.\n",
    "\n",
    "```python\n",
    "myobj.save(\"prediction.mp3\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <img src='images/note_icon.svg' alt=\"Note icon\" width=35 align=center> Note\n",
    "> This last block of code will only work if you are running Jupyter Notebooks on a local computer.  Otherwise, download the .mp3 file from HiPerGator and listen to it on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if running on local system\n",
    "# os.system(\"prediction.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Let's put it all together\n",
    "\n",
    "We can put all of these steps together in a function to make it easier to test more images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whats_for_dinner(image):\n",
    "    myimage = load_img(image, target_size = (224, 224))\n",
    "    myimage = img_to_array(myimage)\n",
    "    myimage = myimage.reshape((1, 224, 224, 3))\n",
    "    myimage = preprocess_input(myimage)\n",
    "    myresult = mymodel.predict(myimage)\n",
    "    mylabel = decode_predictions(myresult)\n",
    "    toplabel = mylabel[0][0]\n",
    "\n",
    "    if toplabel[1] == 'pizza':\n",
    "        sayit = \"Amelia, tonight's dinner is \" + toplabel[1] + \", let's go downstairs for dinner!\"\n",
    "    else:\n",
    "        sayit = \"Amelia, tonight's dinner is \" + toplabel[1] + \", let's stay here and order a pizza!\"\n",
    "\n",
    "    myobj = gTTS(text = sayit)\n",
    "\n",
    "    return mylabel, myobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, soundclip2 = whats_for_dinner('images/pizza2.jpg')\n",
    "print(label)\n",
    "\n",
    "soundclip2.save(\"prediction2.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amelia should test with non-pizza meals too to make sure her system is working. Let's try this burger. ![Photo of a hamburger](images/hamburger.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, soundclip3 = whats_for_dinner('images/hamburger.jpg')\n",
    "print(label)\n",
    "\n",
    "soundclip3.save(\"prediction3.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like Amelia's classifier is working well as it predicted that the image was a cheeseburger. \n",
    "\n",
    "But Amelia's parents are on to her...they started making food that looks like pizza, but isn't! How about this quiche? Does it fool the AI? Can you find images that trick Amelia into coming down for dinner?\n",
    "\n",
    "![A photo of quiche](images/quiche.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, soundclip4 = whats_for_dinner('images/quiche.jpg')\n",
    "print(label)\n",
    "\n",
    "soundclip4.save(\"prediction4.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.6.0",
   "language": "python",
   "name": "tensorflow-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
