{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/Practicum_AI_Logo.white_outline.svg' width=250 alt='Practicum AI logo'> <img src='https://github.com/PracticumAI/practicumai.github.io/blob/main/images/icons/practicumai_beginner.png?raw=true' align='right' width=50>\n",
    "***\n",
    "# *Practicum AI:* Deep Learning - MNIST Classifier\n",
    "\n",
    "This exercise adapted from Baig et al. (2020) <i>The Deep Learning Workshop</i> from <a href=\"https://www.packtpub.com/product/the-deep-learning-workshop/9781839219856\">Packt Publishers</a> (Exercise 2.07, page 92).\n",
    "\n",
    "### MNIST Handwritten Digit Classification Dataset\n",
    "The [MNIST](http://yann.lecun.com/exdb/mnist/) (Modified National Institue of Standards and Technology) training dataset contains 60,000 28Ã—28 pixel grayscale images of handwritten single digits between 0 and 9, with an additional 10,000 images available for testing.  All images in this dataset have been normalized and centered.\n",
    "\n",
    "The MNIST dataset is frequently used in machine learning research and has become a standard benchmark for image classification models. Top-performing models often achieve a classification accuracy above 99%, with an error rate between 0.4 % and 0.2% on the hold-out test dataset.\n",
    "\n",
    "In this exercise, you will implement a deep neural network (multi-layer) capable of classifying these images of handritten digits into one of 10 classes. \n",
    "\n",
    "#### 1. Import libraries\n",
    "\n",
    "Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "# Import Keras libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load the MNIST dataset\n",
    "\n",
    "Import the MNIST dataset from the [Keras module](https://keras.io/api/datasets/mnist/). The `train_features` and `test_features` variables contain the training and test images while `train_labels` and `test_labels` contain the corresponding labels for each item in those datasets.  \n",
    "\n",
    "```python\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_features,train_labels), (test_features,test_labels) = mnist.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Normalize the data\n",
    "\n",
    "Normalize the data by scaling the images so their values are between 0 and 1.\n",
    "\n",
    "```python\n",
    "train_features, test_features = train_features / 255.0, test_features / 255.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Build the sequential model\n",
    "\n",
    "Using the Sequential API, build your model according to the following spec:\n",
    "\n",
    "* First, a flattened layer to unroll 28x28 pixel images into a single array of 782. The model should use the input_shape in the function argument to set the input size in the first layer.\n",
    "* A dense hidden layer with 50 units (neurons) and ReLU activation functions.\n",
    "* A dense hidden layer with 20 units and ReLU activation functions.\n",
    "* A dense output layer with 10 units and the softmax activation function.\n",
    "\n",
    "Your completed neural network should have four layers. Feel free to experiment with different architectures and build your own model.\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(units = 50, activation = 'relu'))\n",
    "model.add(Dense(units = 20 , activation = 'relu'))\n",
    "model.add(Dense(units = 10, activation = 'softmax'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Compile the model\n",
    "\n",
    "To `compile` the model, you need to specify an optimizer, a loss function, and a metric to judge the performance of your model.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Inspect the model configuration using the summary function\n",
    "\n",
    "```python\n",
    "model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model summary indicates that this model has 40,480 parameters (weights and biases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Fit the model to the training data\n",
    "\n",
    "Now train the model on the MNIST dataset, using the `fit` method. Set training to run for 50 epochs.\n",
    "\n",
    "```python\n",
    "model.fit(train_features, train_labels, epochs=50)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Evaluate the model\n",
    "\n",
    "Finally, evaluate the performance of your model on the test set, by calling the model's `evaluate()` method.\n",
    "\n",
    "```python\n",
    "model.evaluate(test_features, test_labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Model predictions\n",
    "\n",
    "Let's see how the model performs on some randomly selected images.  Are its predictions correct?  \n",
    "\n",
    "Randomly select an image from the test dataset, in this case the 200th image.\n",
    "\n",
    "```python\n",
    "loc = 200\n",
    "test_image = test_features[loc]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at the shape of the image.\n",
    "\n",
    "```python\n",
    "test_image.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our image is 28x28 pixels. However, the model needs not just the size of the image but the number of channels as well. A simple call to the `reshape()` method fixes that problem. \n",
    "\n",
    "```python\n",
    "test_image = test_image.reshape(1,28,28)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the model's `predict()` method, assign the output to result, and then view its contents.\n",
    "\n",
    "```python\n",
    "result = model.predict(test_image)\n",
    "print(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the model has returned the probability of 10 predictions, with the highest one being the most likely.  Use the `argmax` function to see the model's prediction.\n",
    "\n",
    "```python\n",
    "result.argmax()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the prediction, check the label of the corresponding image.\n",
    "\n",
    "```python\n",
    "test_labels[loc]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, visualize the image with pyplot.\n",
    "\n",
    "```python\n",
    "plt.imshow(test_features[loc])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
